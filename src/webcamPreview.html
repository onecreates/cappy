<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8" />
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.18.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix@2.2.0/dist/body-pix.min.js"></script>
    <style>
      body {
        margin: 0;
        overflow: hidden;
        background: transparent;
        -webkit-app-region: drag;
        animation: fadeIn 0.3s ease-out;
      }
      
      #webcam-container {
        position: relative;
        width: 230px;
        height: 230px;
        background: transparent;
        clip-path: polygon(50% 0%, 93.3% 25%, 93.3% 75%, 50% 100%, 6.7% 75%, 6.7% 25%);
        -webkit-app-region: drag;
      }

      #webcam-canvas {
        clip-path: polygon(50% 0%, 93.3% 25%, 93.3% 75%, 50% 100%, 6.7% 75%, 6.7% 25%);
        width: 100%;
        height: 100%;
        transform-origin: center;
        transition: transform 0.3s ease;
        object-fit: cover;
      }

      .preview-container {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        display: flex;
        align-items: center;
        justify-content: center;
      }

      #webcam {
        position: absolute;
        width: 1px;
        height: 1px;
        opacity: 0.01;
        pointer-events: none;
      }

      #debug-video {
        position: fixed;
        top: 0;
        left: 0;
        width: 100px;
        height: 100px;
        display: none;
      }

      .loading-overlay {
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        bottom: 0;
        background: rgba(35,35,35,0.9);
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        z-index: 1000;
        backdrop-filter: blur(8px);
        -webkit-backdrop-filter: blur(8px);
        clip-path: polygon(50% 0%, 93.3% 25%, 93.3% 75%, 50% 100%, 6.7% 75%, 6.7% 25%);
      }

      .loading-spinner {
        width: 40px;
        height: 40px;
        border: 3px solid transparent;
        border-top: 3px solid #1de9b6;
        border-radius: 50%;
        animation: spin 1s linear infinite;
        margin-bottom: 12px;
      }

      .loading-text {
        color: #fff;
        font-size: 0.9em;
        letter-spacing: 0.05em;
      }

      @keyframes spin {
        0% { transform: rotate(0deg); }
        100% { transform: rotate(360deg); }
      }

      @keyframes fadeIn {
        from { opacity: 0; transform: scale(0.95); }
        to { opacity: 1; transform: scale(1); }
      }
    </style>
  </head>
  <body>
    <div id="webcam-container">
      <div class="preview-container">
        <canvas id="webcam-canvas" width="230" height="230"></canvas>
      </div>
      <video id="webcam" autoplay playsinline muted></video>
      <video id="debug-video" muted playsinline></video>
      <div class="loading-overlay">
        <div class="loading-spinner"></div>
        <div class="loading-text">Initializing Camera...</div>
      </div>
    </div>

    <script>
      const DEBUG_MODE = false;
      window.blurBgEnabled = false;
      window.selectedBgColor = '#222';
      window.blurStrength = 12; // Default blur strength
      let bodyPixNet = null;
      let isReady = false;
      let segmentationInProgress = false;
      let currentStream = null;
      let isCleaningUp = false;
      let lastFrameTime = 0;
      let frameInterval = 1000 / 30; // 30 FPS target
      let offCanvas, offCtx, mainCtx;

      // Clean up webcam resources
      async function cleanupWebcam() {
        if (isCleaningUp) return;
        isCleaningUp = true;
        
        try {
          if (currentStream) {
            const tracks = currentStream.getTracks();
            tracks.forEach(track => {
              if (track.readyState === 'live') {
                track.stop();
              }
            });
            currentStream = null;
          }

          const video = document.getElementById('webcam');
          if (video) {
            video.srcObject = null;
            video.load();
          }

          const debugVideo = document.getElementById('debug-video');
          if (debugVideo) {
            debugVideo.srcObject = null;
            debugVideo.load();
          }

          const canvas = document.getElementById('webcam-canvas');
          if (canvas && mainCtx) {
            mainCtx.clearRect(0, 0, canvas.width, canvas.height);
          }
        } catch (err) {
          console.error('Error during cleanup:', err);
        } finally {
          isCleaningUp = false;
        }
      }

      window.electronAPI.onSetBlur((enabled) => {
        window.blurBgEnabled = enabled;
        console.log('[PREVIEW] Blur enabled:', enabled);
      });

      window.electronAPI.onSetBlurStrength((strength) => {
        window.blurStrength = strength;
        console.log('[PREVIEW] Blur strength set to:', strength);
      });

      window.electronAPI.onSetBgColor((color) => {
        window.selectedBgColor = color;
      });

      async function setupWebcam() {
        try {
          const video = document.getElementById('webcam');
          const canvas = document.getElementById('webcam-canvas');
          mainCtx = canvas.getContext('2d', { 
            alpha: true,
            willReadFrequently: true
          });
          
          const constraints = {
            video: {
              width: { ideal: 460 }, // Double size for better quality
              height: { ideal: 460 },
              aspectRatio: 1,
              frameRate: { max: 30 }
            }
          };
          
          currentStream = await navigator.mediaDevices.getUserMedia(constraints);
          video.srcObject = currentStream;
          
          if (DEBUG_MODE) {
            const debugVideo = document.getElementById('debug-video');
            debugVideo.srcObject = currentStream;
            debugVideo.style.display = 'block';
          }

          await new Promise((resolve) => {
            video.onloadedmetadata = () => {
              video.play().then(resolve);
            };
          });

          // Create off-screen canvas for processing
          offCanvas = document.createElement('canvas');
          offCanvas.width = video.videoWidth;
          offCanvas.height = video.videoHeight;
          offCtx = offCanvas.getContext('2d', { alpha: true, willReadFrequently: true });            // Initialize BodyPix with optimized settings for real-time performance
          try {
            bodyPixNet = await bodyPix.load({
              architecture: 'MobileNetV1',
              outputStride: 16,
              multiplier: 0.75,
              quantBytes: 2
            });
            
            console.log('[PREVIEW] BodyPix model loaded successfully');
          } catch (err) {
            console.error('[PREVIEW] BodyPix loading error:', err);
            document.querySelector('.loading-text').textContent = 'Error loading background effects.';
          }

          document.querySelector('.loading-overlay').style.display = 'none';
          isReady = true;
          
          // Start frame drawing
          requestAnimationFrame(drawFrame);
          
          return video;
        } catch (err) {
          console.error('Error accessing webcam:', err);
          document.querySelector('.loading-text').textContent = 'Error accessing webcam. Please check permissions.';
          throw err;
        }
      }

      async function drawFrame(timestamp) {
        const video = document.getElementById('webcam');
        const canvas = document.getElementById('webcam-canvas');
        
        if (!video || !video.videoWidth || !mainCtx || !offCtx) {
          requestAnimationFrame(drawFrame);
          return;
        }
        
        // Frame rate control
        if (timestamp - lastFrameTime < frameInterval) {
          requestAnimationFrame(drawFrame);
          return;
        }
        lastFrameTime = timestamp;

        try {
          if (window.blurBgEnabled && bodyPixNet && !segmentationInProgress) {
            segmentationInProgress = true;
            
            // Optimized segmentation settings for real-time performance
            const segmentation = await bodyPixNet.segmentPerson(video, {
              internalResolution: 'medium',
              segmentationThreshold: 0.6,
              maxDetections: 1,
              scoreThreshold: 0.4
            });

            // Create and setup background canvas
            const bgCanvas = document.createElement('canvas');
            bgCanvas.width = video.videoWidth;
            bgCanvas.height = video.videoHeight;
            const bgCtx = bgCanvas.getContext('2d', { alpha: true });

            // Draw and process background
            bgCtx.drawImage(video, 0, 0);
            
            // Apply background effects
            const strength = Math.min(20, Math.max(1, window.blurStrength || 10));
            
            if (window.selectedBgColor && window.selectedBgColor !== '#222') {
              // Solid color background
              bgCtx.fillStyle = window.selectedBgColor;
              bgCtx.fillRect(0, 0, bgCanvas.width, bgCanvas.height);
            } else {
              // Blurred background with enhanced depth
              bgCtx.filter = `blur(${strength}px)`;
              bgCtx.globalAlpha = 0.95;
              bgCtx.drawImage(bgCanvas, 0, 0);
              
              // Add subtle darkening for depth
              bgCtx.fillStyle = 'rgba(0,0,0,0.2)';
              bgCtx.globalCompositeOperation = 'multiply';
              bgCtx.fillRect(0, 0, bgCanvas.width, bgCanvas.height);
              bgCtx.globalCompositeOperation = 'source-over';
            }
            
            // Second pass: Additional depth effect
            if (window.selectedBgColor === '#222') {
                // Add depth with a subtle gradient
                const gradient = bgCtx.createLinearGradient(0, 0, bgCanvas.width, bgCanvas.height);
                gradient.addColorStop(0, 'rgba(0,0,0,0.2)');
                gradient.addColorStop(0.5, 'rgba(0,0,0,0.3)');
                gradient.addColorStop(1, 'rgba(0,0,0,0.4)');
                bgCtx.fillStyle = gradient;
                bgCtx.globalCompositeOperation = 'overlay';
                bgCtx.fillRect(0, 0, bgCanvas.width, bgCanvas.height);
            }
            
            bgCtx.globalCompositeOperation = 'source-over';

            // Draw original video first
            offCtx.clearRect(0, 0, offCanvas.width, offCanvas.height);
            offCtx.drawImage(video, 0, 0);

            // Create a clean mask for the person
            const foregroundMask = bodyPix.toMask(
              segmentation,
              { r: 255, g: 255, b: 255, a: 255 }, // White for person
              { r: 0, g: 0, b: 0, a: 0 } // Transparent for background
            );

            // Apply mask processing for smooth edges
            const maskCanvas = document.createElement('canvas');
            maskCanvas.width = offCanvas.width;
            maskCanvas.height = offCanvas.height;
            const maskCtx = maskCanvas.getContext('2d');

            const maskImgData = new ImageData(
              new Uint8ClampedArray(foregroundMask.data),
              foregroundMask.width,
              foregroundMask.height
            );
            maskCtx.putImageData(maskImgData, 0, 0);

            // Two-pass edge refinement for better performance
            maskCtx.filter = 'blur(2px)';
            maskCtx.drawImage(maskCanvas, 0, 0);
            
            // Add dilate effect to expand mask slightly
            const imageData = maskCtx.getImageData(0, 0, maskCanvas.width, maskCanvas.height);
            const dilatedData = new Uint8ClampedArray(imageData.data);
            for(let y = 1; y < maskCanvas.height-1; y++) {
                for(let x = 1; x < maskCanvas.width-1; x++) {
                    const idx = (y * maskCanvas.width + x) * 4;
                    if(dilatedData[idx] > 0) {
                        // Expand the mask by one pixel in each direction
                        for(let dy = -1; dy <= 1; dy++) {
                            for(let dx = -1; dx <= 1; dx++) {
                                const targetIdx = ((y + dy) * maskCanvas.width + (x + dx)) * 4;
                                dilatedData[targetIdx] = 255;
                            }
                        }
                    }
                }
            }
            maskCtx.putImageData(new ImageData(dilatedData, maskCanvas.width, maskCanvas.height), 0, 0);
            
            // Final smooth pass
            maskCtx.filter = 'blur(1px)';
            maskCtx.drawImage(maskCanvas, 0, 0);

            // Get the processed mask
            const processedMask = maskCtx.getImageData(
              0, 0,
              maskCanvas.width,
              maskCanvas.height
            );

            // Combine foreground (person) with blurred background
            const finalFrame = offCtx.getImageData(0, 0, offCanvas.width, offCanvas.height);
            const bgImageData = bgCtx.getImageData(0, 0, bgCanvas.width, bgCanvas.height);

            for (let i = 0; i < finalFrame.data.length; i += 4) {
              const maskValue = processedMask.data[i];
              // Implement smooth alpha blending at edges
              if (maskValue < 128) {
                // Background pixel
                const alpha = Math.max(0, (128 - maskValue) / 128);
                finalFrame.data[i] = bgImageData.data[i] * alpha + finalFrame.data[i] * (1 - alpha);
                finalFrame.data[i + 1] = bgImageData.data[i + 1] * alpha + finalFrame.data[i + 1] * (1 - alpha);
                finalFrame.data[i + 2] = bgImageData.data[i + 2] * alpha + finalFrame.data[i + 2] * (1 - alpha);
                finalFrame.data[i + 3] = 255;
              }
              // Person pixels are left unchanged from the original video
            }

            offCtx.putImageData(finalFrame, 0, 0);
          } else {
            // Just draw video if blur is disabled
            offCtx.clearRect(0, 0, offCanvas.width, offCanvas.height);
            offCtx.drawImage(video, 0, 0);
          }

          // Draw final result to main canvas
          mainCtx.clearRect(0, 0, canvas.width, canvas.height);
          mainCtx.drawImage(offCanvas, 0, 0, canvas.width, canvas.height);
          
        } catch (error) {
          console.error('[PREVIEW] Frame error:', error);
        } finally {
          segmentationInProgress = false;
          requestAnimationFrame(drawFrame);
        }
      }

      // Event listeners for cleanup
      window.addEventListener('unload', cleanupWebcam);
      document.addEventListener('visibilitychange', () => {
        if (document.hidden) {
          cleanupWebcam();
        }
      });

      // Start webcam setup
      setupWebcam().catch(console.error);
    </script>
  </body>
</html>
